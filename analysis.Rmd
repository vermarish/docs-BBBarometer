---
title: "analysis"
author: "Rishabh Verma"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document:
    toc: true
    theme: cerulean
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message = FALSE, warning = FALSE, include=FALSE}
library(tidyverse)
library(plotly)
```
# Abstract

My phone has a gyroscope and a barometer, which respectively measure rotational velocity and air pressure. This paper centers around the phenomenon that when I touch the screen, the barometer registers a spike in air pressure, likely because the force of my finger causes a volume deflection inside the phone. The gyroscope is susceptible to recording tremors in the hand holding the phone, but if the barometer can indicate WHEN touch input occurs, the gyroscope can indicate WHERE on the screen the touch input occurs. This could be applied to create a malicious background process which can read a user's PIN code with access only to barometer and gyroscope sensor data. This report is a work in progress.

# Presenting the data


```{r message = FALSE}
tidbits <- read_csv("data/data.csv")
```
  
I've made an Android app that, when I hit "start" and "stop", it captures the following data:

Type 1: accelerometer data (includes x/y/z)  
Type 4: gyroscope data (includes x/y/z)  
Type 6: pressure data  
Type -27: touch data  

The numbers 1,4,6 come from the [Android Sensor API](https://developer.android.com/reference/android/hardware/Sensor#constants). I picked the number -27 myself.


```{r include=FALSE}
accelerometer <- tidbits %>% 
  filter(type == 1) %>% 
  select(time, one, two, three) %>% 
  arrange(time)
  
pressure <- tidbits %>% 
  filter(type == 6) %>% 
  select(time, one) %>% 
  arrange(time)

gyroscope <- tidbits %>% 
  filter(type == 4) %>% 
  select(time, one, two, three) %>% 
  arrange(time)

uncalibrated_touch <- tidbits %>% 
  filter(type == -27) %>% 
  select(time, one, two) %>% 
  arrange(time)
```

A tidbit is an event which includes the fields `type, time, one, two, three`. The latter three fields include the sensor reading/event information corresponding to the type.

* For the accelerometer data and the gyroscope data, one/two/three corresponds to x/y/z. 
* For the pressure data, one corresponds to the reading and two/three are null. 
* For the touch data, one/two correspond to x/y location on the screen, and three is null.

Now let's talk about why the touch data needs to be calibrated.

# Cleaning the data

Each data tidbit is timestamped, but **sensor events and touch events use different clocks**. The Android API bases touch timestamps off of the "uptimeMillis" clock and bases sensor timestamps off of the "elapsedRealtimeNanos" clock. These are different time-counting systems, and so I have to convert them. I want to keep the sensor data as accurate as possible, and the touch data only needs to be approximate, so I choose to convert the touch data to match the elapsedRealtimeNanos clock.

You can see the difference in timestamp-system here. I have to remove some of the leading sig figs because the difference occurs in less-significant digits and would otherwise be truncated by R's output.

```{r}
accelerometer %>% select(time) %>% mutate(time = time %% 1e+12) %>% summary()
gyroscope %>% select(time) %>% mutate(time = time %% 1e+12) %>% summary()
pressure %>% select(time) %>% mutate(time = time %% 1e+12) %>% summary()
uncalibrated_touch %>% select(time) %>% mutate(time = time %% 1e+11) %>% summary()
```

To perform the conversion, my app also records two data points at the start and at the stop.

Type -1: uptimeMillis at start and at stop, for touch events (2 data points)
Type -2: elapsedRealtimeNanos at start and at stop, for sensor events (2 data points)

```{r}
uptimeMillisStart <- tidbits %>% 
  filter(type == -1) %>% 
  select(time) %>% 
  slice(1) %>% 
  as.double()

uptimeMillisEnd <- tidbits %>% 
  filter(type == -1) %>% 
  select(time) %>% 
  slice(2) %>% 
  as.double() 

elapsedRealtimeNanosStart <- tidbits %>% 
  filter(type == -2) %>% 
  select(time) %>% 
  slice(1) %>% 
  as.double()

elapsedRealtimeNanosEnd <- tidbits %>% 
  filter(type == -2) %>% 
  select(time) %>% 
  slice(2) %>% 
  as.double()
```

To convert from millis to nanos, the equation is `y = mx+b` where `y` is in nanos, `x` is in millis, `m` is the slope between them (should expect 10^6) and `b` is the y-intercept.

We can confirm the slope using the secant between the start and end points.

```{r}
m = (elapsedRealtimeNanosEnd - elapsedRealtimeNanosStart) / (uptimeMillisEnd - uptimeMillisStart)
(m - 1e+6)/1e+6*100 # percent error from 10^6
```
The above percent-error is very close to zero.

Then for a point $$(x_1,y_1)$$, I can calculate $$b = y_1 - mx_1$$. Then we can convert all of the time data for the touch input
```{r}
b = elapsedRealtimeNanosEnd - m*uptimeMillisEnd

touch <- uncalibrated_touch %>% 
  mutate(time = m*time + b)

touch %>% select(time) %>% mutate(time = time %% 1e+12) %>% summary()
```
That looks better!

# Examining the data: Can this really work?

Now we're going to graph this data. Let 0 and 1 represent the beginning and the end of the touch input. I want a function such that, if I want to graph the middle 50% of the data, I can call the function with parameters start=0.25, end=0.75, and it graphs the proportion of data between those two points.


I have three global variables: the time of `first_touch` and `last_touch`, which correspond to 0 and 1. Their difference is stored in `range`.

I have a function `trim(data, start, end)` which requires as input the data and the proportions to select. It uses the global variables above: `first_touch`, `last_touch`, `range`. It returns the selection of sensor data which matches the time proportion.

I also have a function `scatterplot(data, value, start, end)` which inputs data, the column to display, and the proportions to select. It will `trim()` the data and graph the specified column with timestamps corresponding to touch input overlaid as vertical bars.


```{r include=FALSE}
first_touch = touch %>% 
  select(time) %>%
  min %>%
  as.double

last_touch = touch %>% 
  select(time) %>%
  max %>%
  as.double

range = last_touch - first_touch

## 0 <= start < end <= 1
trim <- function(data, start, end) {
  open = range*start + first_touch
  close = range*end + first_touch
  
  return(data %>%
           filter(time > open & time < close))
}


## Pre-conditions not enforced:
## value = {'one', 'two', 'three', 'one_smooth', 'two_smooth', 'three_smooth'}
## 0 <= start < end <= 1
scatterplot <- function(data, value, start, end) {   
  # Use start/end to find a proportion of the touch input. Then find all sensor data within.
  # (Decided because multiple sensors are used, but there is only one touch dataset)
  
  graph <- data %>%
    trim(start, end) %>%
    ggplot(aes(x=time, y = switch(value,
                                  "one" = one,
                                  "two" = two,
                                  "three" = three,
                                  "one_smooth" = one_smooth,
                                  "two_smooth" = two_smooth,
                                  "three_smooth" = three_smooth)))
  
  graph <- graph + geom_line(colour = "#2222AA") + geom_point(colour = "#2222AA") + scale_y_continuous()
  
  duration <- (range*(end-start) / 1e9 ) %>% round(2) %>% toString()
  
  graph <- graph + ylab(deparse(substitute(data))) + ggtitle(paste(deparse(substitute(data)), value),
                                                             subtitle=paste("Data captured across", duration, "seconds."))
  
  taps <- touch %>% trim(start, end)
  
  for (i in 1:as.integer(count(taps))) {
    time <- slice(taps, i)[1] %>% as.double()
    graph <- graph + geom_vline(xintercept = time, colour = "#EE9955")
  }
  return(graph)
}
```


So what does the data look like? Let's look at the gyroscope sensors and the pressure sensor. **Orange vertical lines represent the occurrence of touch input.**

```{r}
scatterplot(pressure, "one", 0.03, 0.15)
scatterplot(gyroscope, "one", 0.03, 0.15)
scatterplot(gyroscope, "two", 0.03, 0.15)
scatterplot(gyroscope, "three", 0.03, 0.15)
```


Each touch input is accompanied by a spike in the gyroscope data. The direction of this spike on the three axes may be indicative of which way the device rotates while the user taps the screen, which we MIGHT be able to use to determine touch location. The problem with this data is that there are some gyroscope spikes which don't match the touch data as the user shifts the phone in their hand between taps.

The pressure data provides us with a way around this. There is a strong one-to-one relation between pressure spikes and touch events. A touch event occurs just before a pressure spike. This makes sense when your finger pushes a button, the touchscreen detects your finger before your finger makes firm contact with the screen.


So let's start by using peaks in the pressure data to identify the occurrence of touch input.

<!--
Hold a phone in your hands horizontally. Consider pitch/yaw/roll from this orientation.

Vertical lines represent touch input. All touch inputs seem to line up with spikes in the gyro data, but spikes in the gyro data do NOT correspond with touch inputs. As such, we must use the pressure sensor to detect when a touch input occurs. Dataset one seems the most clean (I hypothesize this axis is pitch, because the passcode keyboard is towards the bottom of the screen. because I would expect pitch to vary most with device inputs on the bottom of the screen.)


```{r}
scatterplot(pressure, "one", 0.03, 0.15)
```
-->
### I don't know how to do peak detection..

..but here's my best guess.

Visually, it seems like each peak consists of at least two or three high data points. Let's keep track of the last three taps. If all of these taps exceed **some** threshold, then we've found a peak and we can mark it until the data falls below the threshold again.


<!--
This method is a start, but it could very naively run into two subsequent increases which are part of the same peak, and declare it to be the same peak.

So then perhaps an increase must be followed by a decrease? Once an increase is observed, it will be recorded as a touch event, but no other increase will be observed until we notice a decrease.

How do we notice a decrease? Let's say we first observe an increase. Then we go into watching mode. The function will continue to monotonically increase until it doesn't. I will assume that the pressure will go down from here. The negation of this assumption is that the pressure is jagged.
  

```{}

         /\
        /  \
       /    \
      /      \
     /    
-----
non-jagged assumption
```

```{}
              /\    
             /  \   
        /\  /    \  
       /  \/      \ 
      /            \
     /              \
-----

   jagged counterexample
```     


I pray it will not be jagged. Then a peak will be a simple increase+decrease. I think this assumption is sound for non-trickery touch input.

While watching after an increase, we will continue watching until a decrease occurs. Then we're over the hill, and we can assume the peak will decrease until it is restored to baseline pressure. We will not wait for baseline pressure, we will simply wait a few samples until the tip of the peak has been climbed and pray baseline pressure has arrived, and further pray that the next tap has not yet occurred. In order for a subsequent tap to occur this quickly, we would very nearly need two fingers touching the display simultaneously. I don't think this will happen.
-->
### Thankfully, the pressure sensor can be easily denoised

This whole process will be smoother if we can denoise the data (pun intended). Let's start by computing a 5-tap running average to low-pass filter our data. I wrote a function `smoothen_col(data, value, n)` which applies a LPF to a data column via an $n$-tap running average.



```{r include=FALSE}
library(stats)
```

```{r include=FALSE}
## n: number of filter taps for running average.
smoothen_col <- function(data, value, n) {
  
  column <- switch (value, 
          "one" = data %>% select(one),
          "two" = data %>% select(two),
          "three" = data %>% select(three)
          ) %>% 
    unlist() %>%
    as.numeric()
  
  coeffs <- rep(1/n,n)
  
  column <- stats::filter(column, coeffs) %>% as_tibble()
  column <- switch(value,
                   "one" = column %>% select(one_smooth = x),
                   "two" = column %>% select(two_smooth = x),
                   "three" = column %>% select(three_smooth = x)
                   )
  
  return(bind_cols(data, column))
}

smoothen_all <- function(data, p) {
  
}
```


```{r}
scatterplot(pressure, "one", 0.03, 0.15)

smooth_pressure <- smoothen_col(pressure, "one", 5)
scatterplot(smooth_pressure, "one_smooth", 0.03, 0.15) + geom_hline(yintercept = 992.2594)

```

A 5-tap moving average looks pretty good. I've plotted the mean as a horizontal black line, and it's... okay? It sits at 992.2594, which seems alright for this narrow data window densely filled with touch inputs, but the mean will only be lower when considering data with sparse touch inputs, which is unfortunate. I don't think the mean will be a useful threshold in an actual application.
<!--
What if I do something really crazy? What if I use a running average to keep track of the midline?

If peaks are sparse, the running average will be closer to base pressure. The occasional peak will ensure that it stays a bit higher than that.

If peaks are frequent, the running average will be a bit higher, but probably not too high. They'd be right around midline assuming fantastic sinusoidal oscillation.

So a simple arithmetic mean has the problem that it might be too low in the case of sparse data? Then we need a mean that weights higher terms more heavily. A geometric mean would be counterintuitive, because GM <= AM. We want something greater than AM. Least squares?

Eh, let's just try arithmetic mean for now and see what happens.

Given a start/end proportion, we'll compute a window in time. Then we look at the pressure data, smoothen the data, and find the average on this window. For a peak beginning, we take the naive approach; "when does the function rise above the threshold?"
-->
<!-- This function is in progress.
```{r}
## data: from pressure sensor. cols = [time | one]
## 0 <= start < end <= 1
draw_input <- function(data, start, end) {
  # Smooth factor (# of taps in running-average LPF)
  n = 4
  
  smooth_pressure <- smoothen_col(data, "one", n)
  
  
}

draw_input(pressure, 0.02, 0.15)
```

-->









### What if I try some wavelet denoising for the gyroscope data?
<!--


Let's try a low-pass filter, see if that does the trick.

```{r}
library(seewave)
```

```{r}
smooth_data <- gyroscope %>% 
  select(one) %>% 
  unlist() %>% 
  as.numeric()
  
freq = 1

one_smooth <- fir(smooth_data, f=freq, to=0.2) %>% as_tibble() %>% select(smoothed = V1)

one_smooth <- bind_cols(gyroscope, one_smooth)

graph <- one_smooth %>% 
  ggplot() +
  geom_point(aes(x = time, y = smoothed, color = "raw")) +
  geom_point(aes(x = time, y = one, color = "LPF"))


```


A low-pass filter seems like it can cut the noise, but it cuts too much of the signal as well, and the peaks have become less apparent.

https://www.rdocumentation.org/packages/rwt/versions/1.0.0/topics/denoise

```{r}
library(rwt)
```
-->


We're going to try wavelet denoising. This requires a power of 2 for the sample size.
```{r}
samples = 2^(floor(log2(count(gyroscope)))) %>% as.integer()
gyroscope <- gyroscope %>% slice(1:samples)

smooth_data <- gyroscope %>% 
  select(one) %>% 
  unlist() %>%
  unname()
  
h <- daubcqf(4)  # must be even

one_smooth <- denoise.dwt(smooth_data, h$h.0)[1] %>% as_tibble() %>% select(smoothed = xd)

one_smooth <- bind_cols(gyroscope, one_smooth)

graph <- one_smooth %>% 
  ggplot() +
  geom_point(aes(x = time, y = smoothed, color = "raw")) +
  geom_point(aes(x = time, y = one, color = "LPF"))


taps = dim(touch)[1]

for (i in 1:taps) {
  time <- slice(touch, i)[1] %>% as.double()
  graph <- graph + geom_vline(xintercept = time)
}

graph
```

```{r}
sig <- makesig(SIGNAL.DOPPLER)
h <- daubcqf(6)
ret.dwt <- denoise.dwt(sig$x, h$h.0)
```

```{r}
sig <- makesig(SIGNAL.LIN.CHIRP, 8)
h <- daubcqf(4)
L <- 2
ret.mdwt <- mdwt(sig$x, h$h.0, L)
```



```{r}
one_smooth <- fir(smooth_data, f=freq, to=0.2) %>% as_tibble() %>% select(smoothed = V1)

one_smooth <- bind_cols(gyroscope, one_smooth)

graph <- one_smooth %>% 
  ggplot() +
  geom_point(aes(x = time, y = smoothed, color = "raw")) +
  geom_point(aes(x = time, y = one, color = "LPF"))


taps = dim(touch)[1]

for (i in 1:taps) {
  time <- slice(touch, i)[1] %>% as.double()
  graph <- graph + geom_vline(xintercept = time)
}

graph
```