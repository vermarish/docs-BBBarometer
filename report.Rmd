---
title: "Big Brother Barometer"
author: "Rishabh Verma"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document:
    toc: true
    theme: cerulean
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
## Filepath on my desktop
# setwd("E:\\Desktop\\docs-BBBarometer")

## Filepath on my laptop
setwd("C:\\Users\\risha\\OneDrive\\Desktop\\docs-BBBarometer")
```

# Introduction

My phone has a gyroscope and a barometer, which respectively measure rotational velocity and air pressure. This paper centers around the phenomenon that when I touch the screen, the barometer registers a spike in air pressure, likely because the force of my finger causes a volume deflection inside the phone. The gyroscope is susceptible to recording tremors in the hand holding the phone, but if the barometer can indicate WHEN touch input occurs, the gyroscope can indicate WHERE on the screen the touch input occurs. This could be applied to create a malicious background process which can read a user's PIN code with access only to barometer and gyroscope sensor data. This report is a work in progress.

# Experiment 1

```{r include=FALSE}
tidbits <- read_csv("data/experiment_2.csv")
```



Type 1: accelerometer data (includes x/y/z)  
Type 4: gyroscope data (includes x/y/z)  
Type 6: pressure data  
Type -27: touch data  

Type -1: uptimeMillisecond clock
Type -2: elapsedRealtimeNanos clock
Type -3: i don't remember, but it's prob not important

```{r functions for cleaning, include=FALSE}

type_map <- function(type) {
  if (type == -27) {
    return("touch")
  } else if (type == 1) {
    return("accelerometer")
  } else if (type == 4) {
    return("gyroscope")
  } else if (type == 6) {
    return("pressure")
  } else {
    return("unknown")
  }
}

clean_tidbits <- function(tidbits) {
  ## Get the clocking tidbits
  clocking <- tidbits %>%
    filter(type == -1 | type == -2)
  
  uptimeMillis <- clocking %>%
    filter(type == -1) %>%
    select(time)
  
  elapsedRealtimeNanos <- clocking %>%
    filter(type == -2) %>%
    select(time)
  
  uptimeMillisStart = min(uptimeMillis)
  uptimeMillisEnd = max(uptimeMillis)
  elapsedRealtimeNanosStart = min(elapsedRealtimeNanos)
  elapsedRealtimeNanosEnd = max(elapsedRealtimeNanos)
  
  ## Select the data tidbits
  tidbits <- tidbits %>% 
    filter(type == -27 | type > 0)
  
  calibrated <- tidbits %>%
    filter(type != -27)
  
  # Calibrate the touch-data tidbits
  m = (elapsedRealtimeNanosEnd - elapsedRealtimeNanosStart) / (uptimeMillisEnd - uptimeMillisStart)
  b = elapsedRealtimeNanosEnd - m*uptimeMillisEnd
  
  uncalibrated <- tidbits %>%
    filter(type == -27) %>%
    mutate(time = m*time + b)
  
  ## Combine results and re-format type as string
  tidbits <- bind_rows(calibrated, uncalibrated) %>%
    mutate(type = sapply(type, type_map)) %>%
    arrange(time)
  
  return(tidbits)
}
```

```{r functions for viewing}
data <- clean_tidbits(tidbits)

first_touch = data %>%
  filter(type=="touch") %>%
  select(time) %>%
  min %>%
  as.double

last_touch = data %>% 
  filter(type=="touch") %>%
  select(time) %>%
  max %>%
  as.double

range = last_touch - first_touch

## 0 <= start < end <= 1
trim <- function(data, start, end) {
  open = range*start + first_touch
  close = range*end + first_touch
  
  return(data %>%
           filter(time > open & time < close))
}

# col = {'one', 'two', 'three'}
scatterplot <- function(data, sensor_type, col, 
                        start=0, end=1,
                        size=1, alpha=0.9) {
  graph <- data %>%
    filter(type==sensor_type) %>%
    select(time, col) %>%
    trim(start, end) %>%
    ggplot(aes_string(x="time", y=col))
  
  graph <- graph + geom_line(colour = "#1a9850") + geom_point(colour = "#1a9850") + scale_y_continuous()
  
  # add title and subtitle
  duration <- (range*(end-start) / 1e9 ) %>% round(2) %>% toString()
  title <- paste(sensor_type, col)
  graph <- graph + 
    ylab(title) + 
    ggtitle(label=title,
            subtitle=paste("Data captured across", duration, "seconds."))
  
  # Plot type "touch"
  taps <- data %>%
    filter(type=="touch") %>% 
    trim(start, end)
  tap_times <- taps$time
  for (tap_time in tap_times) {
    graph <- graph + geom_vline(xintercept = tap_time, colour= "#1a9850", size=size, alpha=alpha)
  }
  
  # Plot type "touch_predict"
  guesses <- data %>%
    filter(type=="touch_predict") %>%
    trim(start, end)
  guess_times <- guesses$time
  for (guess_time in guess_times) {
    graph <- graph + geom_vline(xintercept = guess_time, colour="#f46d43", size=size, alpha=alpha)
  }
  
  return(graph)
}

scatterplot(data, "pressure", "one", 0.4, 0.5)
```


Now to detect touch occurrence. I could do something dumb and threshold the pressure data, or I could do something clever and train a model. Perhaps I keep a buffer of the last four pressure readings, or simply the last four changes in pressure reading. This will be tuple of 4 predictors. To form a training dataset, I need responses; perhaps the four-tuple nearest in time

                 |                              |     
. . . . . x x x x|. . .        . . . . . . . . .|x x x x . .
                 |                              |     
nearest in time before            nearest in time after
   (unviable)                            (viable)

can be categorized as 1, and all other four-tuples (excepting maybe the neighboring ones) can be categorized as 0.

After training a binary classifier (logit distribution), we then threshold on the logit probability. 

---

Before I mine the first derivative as my feature, why don't I modify my scatterplot function to show that derivative.
```{r}
scatterplot_d <- function(data, sensor_type, col, start, end) {

  # compute the derivative of the specified column
  col_index <- which(names(data) == col)
  
  sensor_data <- data %>%
    filter(type == sensor_type)
  
  col_vals <- sensor_data[col_index]
  
  left <- col_vals %>% 
    slice(1:(nrow(col_vals)-1))
  right <- col_vals %>% 
    slice(2:(nrow(col_vals)))
  
  deriv <- (right - left) %>%
    select(deriv = one)
  
  # bind this as a new column
  sensor_data <- sensor_data %>%
    slice(2:nrow(sensor_data)) %>%
    bind_cols(deriv)
  
  # add the rows for touch entries back in
  touch_data <- data %>%
    filter(type=="touch") %>%
    mutate(deriv = NA)
  
  treated_data <- bind_rows(sensor_data, touch_data)
  
  scatterplot(data=treated_data, 
              sensor_type=sensor_type,
              col="deriv",
              start=start,
              end=end)
}

#scatterplot_d(data, "pressure", "one", 0.5, 0.55) +
#  geom_hline(yintercept=0, colour="#999999", linetype="dashed")

```

It looks like each pressure spike is registered on about two points. Let's use a window of four derivative values, which requires computation on a window of size five. Around each touch point, I will record two subsequent windows as 

Okay so let's do it. Let's use the first 60\% of the data as training data, and the last 40\% as testing data. With 161 data points in experiment 1, this is 112 data points in training and 48 data points in testing.

```{r}
prop = 0.6  # proportion of training data


## Portion data into train and test
touch_data <- data %>% 
  filter(type=="touch") %>%
  arrange(time)

cutoff <- touch_data$time[as.integer(nrow(touch_data)*prop)]

train <- data %>%
  filter(time < cutoff) %>%
  filter(type %in% c("pressure", "touch")) %>%
  arrange(time)

test <- data %>%
  filter(time > cutoff) %>%
  filter(type %in% c("pressure", "touch")) %>%
  arrange(time)


## Next we build train_df
# input: a dataframe containing pressure_data in a column
# output: a dataframe where each row is the result of point-wise multiplication 
#         between factor 1 and factor 2, and is labeled.
#         factor 1:  iterated difference of pressure signal
#                    (a naive first derivative)
#         factor 2:  an impulse of specified width
#                    e.g. width=3 -> factor_2=[0 ... 0 1 1 1 0 ... 0]
#                    (the impulse is iterated for each row)
#       
#
# and a 5th column for the label
build_df <- function(pressure_data, width) {
  df <- data.frame(matrix(rep(NA,width + 1), nrow=1))
  df <- na.omit(df)
  colnames(df)[ncol(df)] = "label"
  
  i = 1
  quota = 0
  while (i <= nrow(pressure_data) - width) {
    event <- pressure_data %>%
      slice(i:(i+width+1))
    
    pressure_reading <- event %>%
      filter(type == "pressure") %>%
      head(n=width+1) %>%
      .$one
    
    
    if (event$type[1] == "touch") {
      # then don't process it.
      # 
      # instead, start labeling subsequent pressure_events as 1
      # quota is a "hyperparameter" for labeling data
      # this line defines the size of the quota
      quota = 2
    } else {  # event$type[1] == "pressure"
      # then label as 1 only if we need to meet the quota
      if (quota > 0) {
        label = 1
        quota = quota - 1
      } else {
        label = 0
      }
      df[nrow(df)+1,] = c(diff(pressure_reading), label)
    }
    i = i + 1
  }
  return(df)
}
```

Let's just try a logistic regression. I'm concerned this isn't really the best choice of model because we don't have a close-to-even split and the noise may not be gaussian. This also does not leverage the fact that we are dealing with a time series, but let's just try it out.

```{r}
# input: tibbles with the tidbits
# this function will restructure the tidbits for regression,
#                    train the model,
#                    and return the fitting for train and test.
train_pressure_model <- function(train, test, width=4) {
  buffer = width
  
  ## Arrange the data
  train_df <- build_df(train, width=width)
  test_df <- build_df(test, width=width)
  
  ## Fit the model
  touch_model <- glm(label ~ ., 
                     data=train_df,
                     family = "binomial")
  
  ## Handle the values fitted in training
  # Store the fitted values
  result_training <- bind_cols(train %>% 
                        filter(type == "pressure") %>% 
                        slice((buffer):(buffer+nrow(train_df)-1)),
                      touch_model$fitted.values) %>%
    rename(p = ...6)
  
  # Shift the fitted values
  shift <- 3
  result_training_shifted <- result_training
  result_training_shifted$p <- c(
    result_training_shifted$p[(shift+1):nrow(result_training_shifted)],
    rep(0, shift)
  )
  
  ## Handle the values predicted in testing
  # Compute the predicted values
  output <- predict(touch_model, 
          newdata=test_df)
  fitted.values <- 1/(1+exp(-1*(output)))
  
  # Store the predicted values
  result_testing <- bind_cols(test %>% 
                        filter(type == "pressure") %>% 
                        slice((buffer):(buffer+nrow(test_df)-1)),
                      fitted.values) %>%
    rename(p = ...6)
  
  # Shift the fitted
  result_testing_shifted <- result_testing
  result_testing_shifted$p <- c(
    result_testing_shifted$p[(shift+1):nrow(result_testing_shifted)],
    rep(0, shift)
  )
  
  result <- list()
  result$training <- result_training_shifted
  result$testing <- result_testing_shifted
  return(result)
}

result_pair <- train_pressure_model(train, test, width=4)

scatterplot_pressure_model <- function(data, result_pair, a, b) {
  scatterplot(data, "pressure", "one", a, b) +
  geom_line(data=result_pair$testing %>% trim(a,b),
            aes(y= p*diff(range(one)) + min(one)),
            colour="red") +
  geom_line(data=result_pair$training %>% trim(a,b),
            aes(y= p*diff(range(one)) + min(one)),
            colour="#d781d5")
}

scatterplot_pressure_model(data, result_pair, a=0.55, b=0.65)
```
Okay. Now I've got two nice neat functions to pipe training and testing data through a model, and graphically view the results. Let's evaluate the effect of thresholding the modeled confidence of a touch event.

```{r}
# Input a vector containing integers in order
# Collapse chains of many consecutive integers into a single integer
# e.g. 2 4 5 6 8 9 11 12
#  ->  2 4-5-6 8-9 11-12
#  ->  2 4 8 11
eliminate_consecutive_integers <- function(integers) {
  # strategy: shift the entries of the lift by one and compare it against itself
  first <- integers[1:length(integers)-1]
  last <- integers[2:length(integers)]
  last_decrement <- last - 1
  
  
  # the first entry is always valid, but this strategy requires it be indexed separately.
  result <- c(integers[1], 
              last[first != last_decrement])
  return(result)
}


# Input a dataframe with pressure data and the modeled p-confidence of touch occurrence.
# Include the value at which to threshold.
threshold_pressure <- function(result, threshold=0.4) {
  indices <- which(result$p > threshold) %>%
    eliminate_consecutive_integers
  
  occurrence_times <- result %>%
    slice(indices) %>%
    .$time
  
  occurrence_df <- data.frame(type="touch_predict",
             time=occurrence_times,
             one=0,
             two=0,
             three=0,
             p=0)
  
  thresholded <- bind_rows(result, occurrence_df) %>%
    arrange(time)
  
  return(thresholded)
}


thresholded_testing <- threshold_pressure(result_pair$testing, threshold=0.5) %>%
  bind_rows(test %>% filter(type=="touch"))

scatterplot(thresholded_testing, 
            sensor_type="pressure", col="one",
            start=0.8, end=0.9,
            size=1, alpha=0.7)
```




Wow! That looks really good. I really hate proceeding forward without objective measures of everything I do. I really bet our model could be improved using lasso regression, and that would require hyperparameter tuning which is unreliable without a measurable error function, but "time to market" is of more importance.

Let's assume our touch input is good. Let's mine the subsequent gyroscope data for features. 

```{r}

model <- data %>%
  bind_rows(thresholded_testing %>%
              filter(type=="touch_predict") %>%
              select(-p)) %>%
  bind_rows(thresholded_training %>%
              filter(type=="touch_predict") %>%
              select(-p))

model %>% group_by(type) %>% count()

a=0.85
scatterplot(model, "gyroscope", "one", start=a, end=a+0.05, alpha=0.8)
```

Okay next phase! Given touch input (or a proxy for its occurrence), can I identify a relationship between gyroscope data and the location of the touch input?   

Layer: A function that, given a vector of input occurrence and gyroscope data, mines features.

Layer: A function that, given all data, mines gyroscope features. An option should be included to do
toggle A: use "touch" and include touch location as a response
toggle B: use "touch_predict" and do not include touch location as response.


```{r}
# In: signal should be a tibble with two columns: time and data (pressure data)
# Ou: list of features
pull_waveforms <- function(signal, times) {
  features <- list()
  
  for (time in times) {
    center <- which(signal$time > time)[1]
    polarity <- sign(signal$data[center])
    left <- center
    right <- center
    
    while (left > 1 && sign(signal$data[left - 1]) == polarity) {
      left <- left - 1
    }
    while (right < nrow(signal) && sign(signal$data[right + 1]) == polarity) {
      right <- right + 1
    }
    feature <- signal$data[left:right]
    features[[length(features)+1]] = feature
  }
  return(features)
}


# In: TIME-SORTED data tibble with ONLY timestamped gyroscope entries
# Ou: feature tibble containing each wave
mine_features <- function(gyro, times) {
  # columns of tibble:
  #  times
  #  gyro one peaks
  #  gyro two peaks
  #  gyro three peaks
  gyro_one <- pull_waveforms(signal=gyro %>% select(time=time, data=one),
                             times=times)
  
  gyro_two <- pull_waveforms(signal=gyro %>% select(time=time, data=two),
                             times=times)
  gyro_three <- pull_waveforms(signal=gyro %>% select(time=time, data=three),
                             times=times)
  
  return(tibble(gyro_one, gyro_two, gyro_three, times))
}


# In: data tibble with gyroscope and touch entries.
#     touch can be "touch" with x/y in headers $one $two. use labeled=TRUE.
#     or touch can be "touch_guess" with no x/y. use labeled=FALSE.
# Ou: if labeled=TRUE, collect the waveform and features with x/y labels.
# Ou: if labeled=FALSE< collect the waveform and features
gyro_from_touch <- function(data, labeled=TRUE) {
  data <- data %>% arrange(time)
  
  ## Use gyro and touch data to mine features
  gyro <- data %>%
    filter(type == "gyroscope")
  if (labeled) {
    times <- data %>%
      filter(type == "touch") %>%
      .$time
  } else {
    times <- data %>% 
      filter(type == "touch_predict") %>%
      .$time
  }
  features <- mine_features(gyro, times)
  
  ## Add labels
  if (labeled) {
    labels <- data %>%
      filter(type=="touch") %>%
      select(x=one, y=two)
    features <- features %>% bind_cols(labels)
  }
  
  return(features)
}


# For testing
foobar <- model %>% trim(0.3, 0.35)
gyro <- foobar %>% filter(type == "gyroscope")
times <- foobar %>% filter(type == "touch") %>% .$time
signal <- gyro %>% select(time=time, data=one)



gyro_from_touch(model %>% trim(0.7, 0.75), labeled=FALSE)
```

Which features do I mine? 

Perhaps the next 10 datapoints.
Perhaps their slopes.
Perhaps I subsample the next 10 datapoints.
Perhaps the point of greatest absolute value in the neighborhood.
  What is a neighborhood? Is it simply 10 points before and 10 points after? Or maybe I can be clever with it around the zeros. Suppose my pressure data points me to a positive accelerometer peak. I could consider everything between the surrounding zeros as the peak. I could use the width of this peak as a statistical measure.
  
This peak will have n points. How do I mine this peak?????

I really need some sort of book on statistical methods for time series
First let's just get a data structure containing
  X, Y, <peak values>
I don't think dataframes will work with this. It's un-tidy by nature. No fixed number of columns (no schema)
NVM LOL
the trick is to insert a vector of lists as a named column
https://stackoverflow.com/questions/15980281/storing-a-list-within-a-data-frame-element-in-r

```{r}

r1 = c(5,6)
r2 = c(7,8)
r3 = c(9,10)
r4 = c(11,12)

test.df <- data.frame(alpha=c(1,2),
                      bravo=c(3,4))
test.df$charlie = list(r1, r2)
```



