---
title: "Big Brother Barometer"
author: "Rishabh Verma"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document:
    toc: true
    theme: cerulean
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(GGally) # for ggpairs scatterplot matrix
library(ggpubr) # for multiple ggplots in one figure
## Filepath on my desktop
# setwd("E:\\Desktop\\docs-BBBarometer")

## Filepath on my laptop
setwd("C:\\Users\\risha\\OneDrive\\Desktop\\docs-BBBarometer")
```

# Introduction

My phone has a gyroscope and a barometer, which respectively measure rotational velocity and air pressure. This paper centers around the phenomenon that when I touch the screen, the barometer registers a spike in air pressure, likely because the force of my finger causes a volume deflection inside the phone. The gyroscope is susceptible to recording tremors in the hand holding the phone, but if the barometer can indicate WHEN touch input occurs, the gyroscope can indicate WHERE on the screen the touch input occurs. This could be applied to create a malicious background process which can read a user's PIN code with access only to barometer and gyroscope sensor data. This report is a work in progress.

# Experiment 1

```{r include=FALSE}
tidbits <- read_csv("data/experiment_1.csv")
```



Type 1: accelerometer data (includes x/y/z)  
Type 4: gyroscope data (includes x/y/z)  
Type 6: pressure data  
Type -27: touch data  

Type -1: uptimeMillisecond clock
Type -2: elapsedRealtimeNanos clock
Type -3: i don't remember, but it's prob not important

```{r functions for cleaning, include=FALSE}

type_map <- function(type) {
  if (type == -27) {
    return("touch")
  } else if (type == 1) {
    return("accelerometer")
  } else if (type == 4) {
    return("gyroscope")
  } else if (type == 6) {
    return("pressure")
  } else {
    return("unknown")
  }
}

clean_tidbits <- function(tidbits) {
  ## Get the clocking tidbits
  clocking <- tidbits %>%
    filter(type == -1 | type == -2)
  
  uptimeMillis <- clocking %>%
    filter(type == -1) %>%
    select(time)
  
  elapsedRealtimeNanos <- clocking %>%
    filter(type == -2) %>%
    select(time)
  
  uptimeMillisStart = min(uptimeMillis)
  uptimeMillisEnd = max(uptimeMillis)
  elapsedRealtimeNanosStart = min(elapsedRealtimeNanos)
  elapsedRealtimeNanosEnd = max(elapsedRealtimeNanos)
  
  ## Select the data tidbits
  tidbits <- tidbits %>% 
    filter(type == -27 | type > 0)
  
  calibrated <- tidbits %>%
    filter(type != -27)
  
  # Calibrate the touch-data tidbits
  m = (elapsedRealtimeNanosEnd - elapsedRealtimeNanosStart) / (uptimeMillisEnd - uptimeMillisStart)
  b = elapsedRealtimeNanosEnd - m*uptimeMillisEnd
  
  uncalibrated <- tidbits %>%
    filter(type == -27) %>%
    mutate(time = m*time + b)
  
  ## Combine results and re-format type as string
  tidbits <- bind_rows(calibrated, uncalibrated) %>%
    mutate(type = sapply(type, type_map)) %>%
    arrange(time)
  
  return(tidbits)
}
```

```{r functions for viewing}
data <- clean_tidbits(tidbits)

first_touch = data %>%
  filter(type=="touch") %>%
  select(time) %>%
  min %>%
  as.double

last_touch = data %>% 
  filter(type=="touch") %>%
  select(time) %>%
  max %>%
  as.double

range = last_touch - first_touch

## 0 <= start < end <= 1
trim <- function(data, start, end) {
  open = range*start + first_touch
  close = range*end + first_touch
  
  return(data %>%
           filter(time > open & time < close))
}

# col = {'one', 'two', 'three'}
scatterplot <- function(data, sensor_type, col, 
                        start=0, end=1,
                        size=1, alpha=0.9) {
  graph <- data %>%
    filter(type==sensor_type) %>%
    select(time, col) %>%
    trim(start, end) %>%
    ggplot(aes_string(x="time", y=col))
  
  graph <- graph + geom_line(colour = "#1a9850") + geom_point(colour = "#1a9850") + scale_y_continuous()
  
  # add title and subtitle
  duration <- (range*(end-start) / 1e9 ) %>% round(2) %>% toString()
  title <- paste(sensor_type, col)
  graph <- graph + 
    ylab(title) + 
    ggtitle(label=title,
            subtitle=paste("Data captured across", duration, "seconds."))
  
  # Plot type "touch"
  taps <- data %>%
    filter(type=="touch") %>% 
    trim(start, end)
  tap_times <- taps$time
  for (tap_time in tap_times) {
    graph <- graph + geom_vline(xintercept = tap_time, colour= "#1a9850", size=size, alpha=alpha)
  }
  
  # Plot type "touch_predict"
  guesses <- data %>%
    filter(type=="touch_predict") %>%
    trim(start, end)
  guess_times <- guesses$time
  for (guess_time in guess_times) {
    graph <- graph + geom_vline(xintercept = guess_time, colour="#f46d43", size=size, alpha=alpha)
  }
  
  return(graph)
}

scatterplot(data, "pressure", "one", 0.7, 0.75)
```


Now to detect touch occurrence. I could do something dumb and threshold the pressure data, or I could do something clever and train a model. Perhaps I keep a buffer of the last four pressure readings, or simply the last four changes in pressure reading. This will be tuple of 4 predictors. To form a training dataset, I need responses; perhaps the four-tuple nearest in time

                 |                              |     
. . . . . x x x x|. . .        . . . . . . . . .|x x x x . .
                 |                              |     
nearest in time before            nearest in time after
   (unviable)                            (viable)

can be categorized as 1, and all other four-tuples (excepting maybe the neighboring ones) can be categorized as 0.

After training a binary classifier (logit distribution), we then threshold on the logit probability. 

---

Before I mine the first derivative as my feature, why don't I modify my scatterplot function to show that derivative.
```{r}
scatterplot_d <- function(data, sensor_type, col, start, end) {

  # compute the derivative of the specified column
  col_index <- which(names(data) == col)
  
  sensor_data <- data %>%
    filter(type == sensor_type)
  
  col_vals <- sensor_data[col_index]
  
  left <- col_vals %>% 
    slice(1:(nrow(col_vals)-1))
  right <- col_vals %>% 
    slice(2:(nrow(col_vals)))
  
  deriv <- (right - left) %>%
    select(deriv = one)
  
  # bind this as a new column
  sensor_data <- sensor_data %>%
    slice(2:nrow(sensor_data)) %>%
    bind_cols(deriv)
  
  # add the rows for touch entries back in
  touch_data <- data %>%
    filter(type=="touch") %>%
    mutate(deriv = NA)
  
  treated_data <- bind_rows(sensor_data, touch_data)
  
  scatterplot(data=treated_data, 
              sensor_type=sensor_type,
              col="deriv",
              start=start,
              end=end)
}

#scatterplot_d(data, "pressure", "one", 0.5, 0.55) +
#  geom_hline(yintercept=0, colour="#999999", linetype="dashed")
```

It looks like each pressure spike is registered on about two points. Let's use a window of four derivative values, which requires computation on a window of size five. Around each touch point, I will record two subsequent windows as 

Okay so let's do it. Let's use the first 60\% of the data as training data, and the last 40\% as testing data. With 161 data points in experiment 1, this is 112 data points in training and 48 data points in testing.

```{r}
prop = 0.6  # proportion of training data


## Portion data into train and test
touch_data <- data %>% 
  filter(type=="touch") %>%
  arrange(time)

cutoff <- touch_data$time[as.integer(nrow(touch_data)*prop)]

train <- data %>%
  filter(time < cutoff) %>%
  filter(type %in% c("pressure", "touch")) %>%
  arrange(time)

test <- data %>%
  filter(time > cutoff) %>%
  filter(type %in% c("pressure", "touch")) %>%
  arrange(time)


## Next we build train_df
# input: a dataframe containing pressure_data in a column
# output: a dataframe where each row is the result of point-wise multiplication 
#         between factor 1 and factor 2, and is labeled.
#         factor 1:  iterated difference of pressure signal
#                    (a naive first derivative)
#         factor 2:  an impulse of specified width
#                    e.g. width=3 -> factor_2=[0 ... 0 1 1 1 0 ... 0]
#                    (the impulse is iterated for each row)
#       
#
# and a 5th column for the label
build_df <- function(pressure_data, width) {
  df <- data.frame(matrix(rep(NA,width + 1), nrow=1))
  df <- na.omit(df)
  colnames(df)[ncol(df)] = "label"
  
  i = 1
  quota = 0
  while (i <= nrow(pressure_data) - width) {
    event <- pressure_data %>%
      slice(i:(i+width+1))
    
    pressure_reading <- event %>%
      filter(type == "pressure") %>%
      head(n=width+1) %>%
      .$one
    
    
    if (event$type[1] == "touch") {
      # then don't process it.
      # 
      # instead, start labeling subsequent pressure_events as 1
      # quota is a "hyperparameter" for labeling data
      # this line defines the size of the quota
      quota = 2
    } else {  # event$type[1] == "pressure"
      # then label as 1 only if we need to meet the quota
      if (quota > 0) {
        label = 1
        quota = quota - 1
      } else {
        label = 0
      }
      df[nrow(df)+1,] = c(diff(pressure_reading), label)
    }
    i = i + 1
  }
  return(df)
}
```

Let's just try a logistic regression. I'm concerned this isn't really the best choice of model because we don't have a close-to-even split and the noise may not be gaussian. This also does not leverage the fact that we are dealing with a time series, but let's just try it out.

```{r}
# input: tibbles with the tidbits, and a width parameter
# this function will restructure the tidbits for regression,
#                    train the model,
#                    and return the fitting for train and test.
# the width describes the size of the window passed across the signal
# the windowed signal is used in logistic regression
train_pressure_model <- function(train, test, width=4) {
  buffer = width
  
  ## Arrange the data
  train_df <- build_df(train, width=width)
  test_df <- build_df(test, width=width)
  
  ## Fit the model
  touch_model <- glm(label ~ ., 
                     data=train_df,
                     family = "binomial")
  
  ## Handle the values fitted in training
  # Store the fitted values
  result_training <- bind_cols(train %>% 
                        filter(type == "pressure") %>% 
                        slice((buffer):(buffer+nrow(train_df)-1)),
                      touch_model$fitted.values) %>%
    rename(p = ...6)
  
  # Shift the fitted values
  shift <- 3
  result_training_shifted <- result_training
  result_training_shifted$p <- c(
    result_training_shifted$p[(shift+1):nrow(result_training_shifted)],
    rep(0, shift)
  )
  
  ## Handle the values predicted in testing
  # Compute the predicted values
  output <- predict(touch_model, 
          newdata=test_df)
  fitted.values <- 1/(1+exp(-1*(output)))
  
  # Store the predicted values
  result_testing <- bind_cols(test %>% 
                        filter(type == "pressure") %>% 
                        slice((buffer):(buffer+nrow(test_df)-1)),
                      fitted.values) %>%
    rename(p = ...6)
  
  # Shift the fitted
  result_testing_shifted <- result_testing
  result_testing_shifted$p <- c(
    result_testing_shifted$p[(shift+1):nrow(result_testing_shifted)],
    rep(0, shift)
  )
  
  result <- list()
  result$training <- result_training_shifted
  result$testing <- result_testing_shifted
  return(result)
}

result_pair <- train_pressure_model(train, test, width=4)

scatterplot_pressure_model <- function(data, result_pair, a, b) {
  scatterplot(data, "pressure", "one", a, b) +
  geom_line(data=result_pair$testing %>% trim(a,b),
            aes(y= p*diff(range(one)) + min(one)),
            colour="red") +
  geom_line(data=result_pair$training %>% trim(a,b),
            aes(y= p*diff(range(one)) + min(one)),
            colour="#d781d5")
}

scatterplot_pressure_model(data, result_pair, a=0.55, b=0.65)
```
Okay. Now I've got two nice neat functions to pipe training and testing data through a model, and graphically view the results. Let's evaluate the effect of thresholding the modeled confidence of a touch event.

```{r}
# Input a vector containing integers in order
# Collapse chains of many consecutive integers into a single integer
# e.g. 2 4 5 6 8 9 11 12
#  ->  2 4-5-6 8-9 11-12
#  ->  2 4 8 11
eliminate_consecutive_integers <- function(integers) {
  # strategy: shift the entries of the lift by one and compare it against itself
  first <- integers[1:length(integers)-1]
  last <- integers[2:length(integers)]
  last_decrement <- last - 1
  
  
  # the first entry is always valid, but this strategy requires it be indexed separately.
  result <- c(integers[1], 
              last[first != last_decrement])
  return(result)
}


# Input a dataframe with pressure data and the modeled p-confidence of touch occurrence.
# Include the value at which to threshold.
threshold_pressure <- function(result, threshold=0.4) {
  indices <- which(result$p > threshold) %>%
    eliminate_consecutive_integers
  
  occurrence_times <- result %>%
    slice(indices) %>%
    .$time
  
  occurrence_df <- data.frame(type="touch_predict",
             time=occurrence_times,
             one=0,
             two=0,
             three=0,
             p=0)
  
  thresholded <- bind_rows(result, occurrence_df) %>%
    arrange(time)
  
  return(thresholded)
}

thresholded_training <- threshold_pressure(result_pair$testing, threshold=0.5) %>%
  bind_rows(test %>% filter(type=="touch"))

thresholded_testing <- threshold_pressure(result_pair$testing, threshold=0.5) %>%
  bind_rows(test %>% filter(type=="touch"))

scatterplot(thresholded_testing, 
            sensor_type="pressure", col="one",
            start=0.8, end=0.9,
            size=1, alpha=0.7)
```




Wow! That looks really good. I really hate proceeding forward without objective measures of everything I do. I really bet our model could be improved using lasso regression, and that would require hyperparameter tuning which is unreliable without a measurable error function, but "time to market" is of more importance.

Let's assume our touch input is good. Let's mine the subsequent gyroscope data for features. 

```{r}

model <- data %>%
  bind_rows(thresholded_testing %>%
              filter(type=="touch_predict") %>%
              select(-p)) %>%
  bind_rows(thresholded_training %>%
              filter(type=="touch_predict") %>%
              select(-p))

model %>% group_by(type) %>% count()

a=0.85
scatterplot(model, "gyroscope", "one", start=a, end=a+0.05, alpha=0.8)
```

Okay next phase! Given touch input (or a proxy for its occurrence), can I identify a relationship between gyroscope data and the location of the touch input?   

Which features do I mine? 

Perhaps the next 10 datapoints.
Perhaps their slopes.
Perhaps I subsample the next 10 datapoints.
Perhaps the point of greatest absolute value in the neighborhood.
  What is a neighborhood? Is it simply 10 points before and 10 points after? Or maybe I can be clever with it around the zeros. Suppose my pressure data points me to a positive accelerometer peak. I could consider everything between the surrounding zeros as the peak. I could use the width of this peak as a statistical measure.
  
This peak will have n points. How do I mine this peak?????

I really need some sort of book on statistical methods for time series

```{r}
# In: signal should be a tibble with two columns: time and data (pressure data)
#     times should be a vector of doubles.
# Ou: list of waveforms. (each waveform is itself represented as a list)
pull_waveforms <- function(signal, times) {
  features <- list()
  
  for (time in times) {
    center <- which(signal$time > time)[1]
    polarity <- sign(signal$data[center])
    left <- center
    right <- center
    
    while (left > 1 && sign(signal$data[left - 1]) == polarity) {
      left <- left - 1
    }
    while (right < nrow(signal) && sign(signal$data[right + 1]) == polarity) {
      right <- right + 1
    }
    feature <- signal$data[left:right]
    features[[length(features)+1]] = feature
  }
  return(features)
}


# In: TIME-SORTED data tibble with ONLY timestamped gyroscope entries
# Ou: feature tibble containing each wave
mine_features <- function(gyro, times) {
  # Mining features with pull_waveforms works better when delayed by 7-10 samples, to get closer to the center of a peak.
  delay <- 10
  period <- gyro$time %>% diff %>% mean
  times <- times + delay*period
  
  gyro_one <- pull_waveforms(signal=gyro %>% select(time=time, data=one),
                             times=times)
  
  gyro_two <- pull_waveforms(signal=gyro %>% select(time=time, data=two),
                             times=times)
  gyro_three <- pull_waveforms(signal=gyro %>% select(time=time, data=three),
                             times=times)
  
  # mine the extremum of each waveform as a feature
  extremum_one <- gyro_one %>% sapply(function(waveform) {sign(waveform[[1]][1]) * max(abs(waveform[[1]]))})
  extremum_two <- gyro_two %>% sapply(function(waveform) {sign(waveform[[1]][1]) * max(abs(waveform[[1]]))})
  extremum_three <- gyro_three %>% sapply(function(waveform) {sign(waveform[[1]][1]) * max(abs(waveform[[1]]))})
  
  return(tibble(gyro_one, gyro_two, gyro_three, 
                extremum_one, extremum_two, extremum_three,
                times))
}


# In: data tibble with gyroscope and touch entries.
#     touch can be "touch" with x/y in headers $one $two. use labeled=TRUE.
#     or touch can be "touch_guess" with no x/y. use labeled=FALSE.
# Ou: if labeled=TRUE, collect the waveform and features with x/y labels.
# Ou: if labeled=FALSE, collect the waveform and features
gyro_from_touch <- function(data, labeled=TRUE) {
  data <- data %>% arrange(time)
  
  ## Use gyro and touch data to mine features
  gyro <- data %>%
    filter(type == "gyroscope")
  if (labeled) {
    times <- data %>%
      filter(type == "touch") %>%
      .$time
  } else {
    times <- data %>% 
      filter(type == "touch_predict") %>%
      .$time
  }
  features <- mine_features(gyro, times)
  
  ## Add labels
  if (labeled) {
    labels <- data %>%
      filter(type=="touch") %>%
      select(x=one, y=two)
    features <- features %>% bind_cols(labels)
  }
  
  return(features)
}


# For testing
foobar <- model %>% trim(0.3, 0.35)
gyro <- foobar %>% filter(type == "gyroscope")
times <- foobar %>% filter(type == "touch") %>% .$time
signal <- gyro %>% select(time=time, data=one)

gyro_from_touch(model %>% trim(0.7, 0.75), labeled=TRUE)
```

Great. It only took 300+ lines of code to get here, from the data presented by the Android app to an actual workable tidy learnable format. I'm going to encapsulate this in one function. I'm also going to use the output of the pressure model as a feature.

```{r}
# In: tibble of pressure data with columns `time` and `p`, 
#     vector of times
# Ou: a feature vector containing the strongest p-value
pull_pressure_features <- function(result_pair, times) {
  pressure_data <- bind_rows(result_pair$testing %>% mutate(stage="testing"),
                             result_pair$training %>% mutate(stage="training")) %>%
    select(time, p, stage) %>%
    arrange(time)
  
  i <- 1
  features <- c()
  for (time in times) {
    index <- which(pressure_data$time > time)[1]
    values <- pressure_data$p[(index-2):(index+5)]
    features[i] <- max(values)
    i <- i + 1
  }
  return(features)
}

build_experiment <- function(tidbits=NULL, path="data/experiment_1.csv") {
  if (is.null(tidbits)) {
    tidbits <- read_csv(path)
  }
  
  data <- clean_tidbits(tidbits)
  
  ## Build dataframes for train and test
  ## 60/40 split
  prop = 0.6
  touch_data <- data %>%
  	filter(type == "touch") %>%
  	arrange(time)
  cutoff <- touch_data$time[as.integer(nrow(touch_data)*prop)]
  train <- data %>%
    filter(time < cutoff) %>%
    filter(type %in% c("pressure", "touch")) %>%
    arrange(time)
  test <- data %>%
    filter(time > cutoff) %>%
    filter(type %in% c("pressure", "touch")) %>%
    arrange(time)
  
  
  ## Use pressure data to build a pressure model,
  result_pair <- train_pressure_model(train, test, width=4)

  ## threshold the pressure model for touch_predict tidbits
  thresholded_testing <- threshold_pressure(result_pair$testing, threshold=0.5) %>%
    bind_rows(test %>% filter(type=="touch"))
  ## and combine the results
  model <- data %>%
    bind_rows(thresholded_testing %>%
                filter(type=="touch_predict") %>%
                select(-p)) %>%
    bind_rows(thresholded_training %>%
                filter(type=="touch_predict") %>%
                select(-p))
  
  exp_data <- gyro_from_touch(model, labeled=TRUE) %>%
    mutate(deflection = pull_pressure_features(result_pair, times))

  
  result <- list()
  result$exp_data <- exp_data
  result$pressure_training <- result_pair$training
  result$pressure_testing <- result_pair$testing
  return(result)
}

```

<TODO>
Wait hold up. I need to modify the function above so that when I mine exp_data, I also get a feature from the pressure data. I'll need a helper function so that I can input a vector of times and the p-model data, and it'll mine features for me. I thought about re-using pull_waveforms, but that pulls from zero-centered data. My p-model goes between 0 and 1, so........ maybe check the three values before and the five values after and get the max. That'll be my feature.

```{r}

```
</TODO>

Alright. Experiment one. Can I discern left/right movement?

```{r}
exp1_data <- build_experiment(path="data/experiment_1.csv") %>%
  .$exp_data %>%
  mutate(side = ifelse(x > 500, "right", "left"))

# The experiment is distributed left/right
exp1_data %>% 
  ggplot(aes(x=x, y=y)) +
  geom_point() +
  theme(aspect.ratio=2400/1080) +      ##formatting
  scale_y_reverse(limits=c(2400,0)) +  ##
  scale_x_continuous(limits=c(0,1080), ##
                     position="top") + ##
  ggtitle("Experiment 1:", subtitle="Can we discern left from right?")

# This scatterplot matrix indicates relation with extrema from two and three
ggpairs(exp1_data, 
        columns=c(4:6,8),
        mapping = ggplot2::aes(color=side))


bounds <- exp1_data[4:6] %>% abs() %>% max()

exp1_data %>%
  ggplot(aes(x=extremum_two, y=extremum_three, color=side)) +
  geom_point() +
  geom_hline(yintercept=0, color="#aaaaaa") + 
  geom_vline(xintercept=0, color="#aaaaaa") + 
  xlim(-bounds, bounds) +
  ylim(-bounds, bounds)
  ggtitle("Experiment 1 is discernible")
  
# For SEAL application
fig1a <- exp1_data %>% 
  ggplot(aes(x=x, y=y, color=side)) +
  geom_point() +
  theme(aspect.ratio=2400/1080) +      ##formatting
  scale_y_reverse(limits=c(2400,0)) +  ##
  scale_x_continuous(limits=c(0,1080), ##
                     position="top") + ##
  ggtitle("Taps on phone display") +
  xlab("horizontal pixels") +
  ylab("vertical pixels")

fig1a

fig1b <- exp1_data %>%
  ggplot(aes(x=extremum_two, y=extremum_three, color=side)) +
  geom_point() +
  geom_hline(yintercept=0, color="#aaaaaa") + 
  geom_vline(xintercept=0, color="#aaaaaa") + 
  xlim(-bounds, bounds) +
  ylim(-bounds, bounds) +
  xlab("Rotation on y-axis") +
  ylab("Rotation on z-axis") +
  ggtitle("Latent space")

fig1b

fig1 <- ggarrange(fig1a, fig1b, common.legend=TRUE, legend="bottom") #TODO export for SEAL
```

I can in fact discern left/right movement. Visually, I can already tell that simple decision tree classification would work well for this experiment. I must remember that while experiment 1 is binary classification, the final problem is regression.


Experiment two: Do taps in the center vs. the edge differ in pressure deviation?
 TODO
```{r}
exp2 <- build_experiment(path="data/experiment_2.csv")

exp2_data <- exp2 %>%
  .$exp_data %>%
  mutate(side = ifelse(y > 1800, "lower", "center"))

exp2_pressure_testing <- exp2$pressure_testing

# The experiment is distributed center/lower
exp2_data %>% 
  ggplot(aes(x=x, y=y, color=side)) +
  geom_point() +
  theme(aspect.ratio=2400/1080) +      ##formatting
  scale_y_reverse(limits=c(2400,0)) +  ##
  scale_x_continuous(limits=c(0,1080), ##
                     position="top") + ##
  ggtitle("Experiment 2:", subtitle="Can we discern center from lower?")


ggpairs(exp2_data, 
        columns=c(4:6, 9),
        mapping = ggplot2::aes(color=side))


bounds <- exp2_data[4:6] %>% abs() %>% max()

exp2_data %>%
  ggplot(aes(x=extremum_two, y=extremum_three, color=side)) +
  geom_point() +
  geom_hline(yintercept=0, color="#aaaaaa") + 
  geom_vline(xintercept=0, color="#aaaaaa") + 
  xlim(-bounds, bounds) +
  ylim(-bounds, bounds) +
  ggtitle("Experiment 2 is not discernible with gyro")
```
  
TODO the data shows this experiment is not answerable by gyro data. I will have to see about using pressure height. This will require getting my hands dirty with the functions, so I will do this later.

TODO ya know, this plot demonstrates that usage of a scatterplot isn't really smart here. The human eye isn't so great at discerning patterns in point clouds. If I learned anything from CSE 412, it's that I can aggregate. Perhaps I can use a diverging colorscheme with a visible center (RdYlBu) to indicate confusion between the two classes. Then, in order to indicate a lack of data, I could alter the luminesence or saturation of the color, or I could even re-add the points on top of the aggregation.

Experiment three:
```{r}
group_by_quantile <- function(vec, num_of_groups=4) {
  breaks <- seq(from=0, to=1, length.out=num_of_groups+1)
  quantiles <- quantile(vec, probs=breaks)
  boundaries <- quantiles[2:length(quantiles)]
  
  class <- vec %>% sapply(function(x) {
    which(x <= boundaries)[1]
  })
  
  return(factor(unname(class)))
}


exp3_data <- build_experiment(path="data/experiment_3.csv") %>%
  .$exp_data %>%
  mutate(quartile=group_by_quantile(x+y))

# The experiment is distributed in an arc
exp3_map <- exp3_data %>% 
  ggplot(aes(x=x, y=y, color=quartile)) +
  geom_point() +
  theme(aspect.ratio=2400/1080) +      ##formatting
  scale_y_reverse(limits=c(2400,0)) +  ##
  scale_x_continuous(limits=c(0,1080), ##
                     position="top") + ##
  ggtitle("Experiment 3:", subtitle="A simple regression problem\n(one response variable)")


# If x and y were distributed in a quarter circle, I would compute the angle of each point around the circle to do regression on a single variable
# Since x and y are strongly collinear (r=0.97), I can safely discard one of the responses.

# This scatterplot matrix indicates
exp3_matrix <- ggpairs(exp3_data, 
        columns=c(4:6,8),
        mapping = ggplot2::aes(color=quartile))

bounds <- exp3_data[4:6] %>% abs() %>% max()

exp3_space_all <- exp3_data %>%
  ggplot(aes(x=extremum_one, y=extremum_two, color=quartile)) +
  geom_point(size=2, alpha=0.8) +
  geom_hline(yintercept=0, color="#aaaaaa") + 
  geom_vline(xintercept=0, color="#aaaaaa") + 
  xlim(-bounds, bounds) +
  ylim(-bounds, bounds) +
  ggtitle("Experiment 3", 
          subtitle="the space seems too cloudy for regression..") +
  xlab("Rotation on x-axis") +
  ylab("Rotation on y-axis")

exp3_space_filter <- exp3_data %>%
  filter(quartile %in% c(1,3)) %>%
  ggplot(aes(x=extremum_one, y=extremum_two, color=quartile)) +
  geom_point(size=2, alpha=0.8) +
  geom_hline(yintercept=0, color="#aaaaaa") + 
  geom_vline(xintercept=0, color="#aaaaaa") + 
  xlim(-bounds, bounds) +
  ylim(-bounds, bounds) +
  ggtitle("",subtitle="but the results show separation on a medium scale.") +
  xlab("Rotation on x-axis") +
  ylab("Rotation on y-axis")

exp3_space <- ggarrange(exp3_space_all, exp3_space_filter)

exp3_map
exp3_matrix
exp3_space


fig3a <- exp3_map + 
  ggtitle("Taps on phone display", subtitle=NULL) +
  xlab("horizontal pixels") +
  ylab("vertical pixels")
fig3b <-  ggarrange(exp3_space_all + 
                      ggtitle("Latent space", subtitle=NULL),
                    exp3_space_filter + 
                      ggtitle("Latent space", subtitle="first and third quartiles only"),
                    nrow=2,
                    ncol=1,
                    legend=FALSE)
fig3b

fig3 <- ggarrange(fig3a, fig3b, common.legend=TRUE, legend="bottom")
fig3
```

Okay. I haven't finished experiment 2 yet, but experiments 1 and 3 have given me some faith in this project.

Let's try a realistic dataset.

```{r}
exp4 <- build_experiment(path="data/raw 3-28-2021.csv")

exp4_data <- exp4$exp_data %>%
  mutate(col = 1*(x<380) + 2*(380<x&x<700) + 3*(700<x),
         row = 1*(y<1550) + 2*(1550<y&y<1680) + 3*(1680<y&y<1880) + 4*(1880<y)) %>%
  mutate(digit = ifelse(row==4, 0, col+3*row-3))

# The deflection is strangely distributed. 
# There are two modes, visually separable around the median of 0.8.
hist(exp4_data$deflection, breaks=20)
quantile(exp4_data$deflection)
# Coloring exp4_map with group_by_quantile(deflection, num_of_groups=[2 or 4])
# suggests that there's something valuable here, separating the bottom of the
# screen (digits 0 and 8) from the rest.
# To further examine, I will try a continuous color scale.
# It would be nice to find a transform that makes this distribution uniform, but
# simple tricks don't seem to work. Thus, I will try something impractical and 
# check the rank variables.

exp4_data <- exp4_data %>%
  arrange(deflection) %>%
  mutate(deflection_rank=1:nrow(exp4_data)) %>%
  arrange(times)


exp4_map <- exp4_data %>% 
  ggplot(aes(x=x, y=y, color=deflection_rank)) +
  geom_point(size=3, alpha=0.5) +
  scale_color_viridis_c() +
  theme(aspect.ratio=2400/1080) +      ##formatting
  scale_y_reverse(limits=c(2400,0)) +  ##
  scale_x_continuous(limits=c(0,1080), ##
                     position="top") + ##
  ggtitle("Experiment 4:", subtitle="A real-world scenario")


exp4_matrix <- ggpairs(exp4_data, 
        columns=c(4:6,8))

exp4_map
exp4_matrix

fig4 <- exp4_map +
  xlab("horizontal pixels") +
  ylab("vertical pixels") +
  ggtitle("Taps on phone display", subtitle="ranked by amount of deflection in pressure sensor")
```

TODO I've got to label this data by row, col, number.
    (c1)  (c3)
(r1)  1  2  3    
      4  5  6
      7  8  9
(r4)     0       

c1-c2-c3 breaks at 380 and 700

r1-r2-r3-r4 breaks at 1550, 1680, 1880

then the digit at row $r < 4$ and col $c$ is $$c+ 3r - 3$$,
and the digit at row 4 is 0.